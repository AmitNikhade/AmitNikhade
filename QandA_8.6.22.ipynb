{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jar.beta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d1d6eae623a4bc78086b32fbcf232ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9c935703527464e9d76ea2266822466",
              "IPY_MODEL_e6671f43925e470c9a8ef83b0e0698fb",
              "IPY_MODEL_9a3f0edf677b4ab995e39b97cb98ddda"
            ],
            "layout": "IPY_MODEL_a999788b71514179aed78eed08a43e68"
          }
        },
        "a9c935703527464e9d76ea2266822466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24973a24562a44d492e70fe734887450",
            "placeholder": "​",
            "style": "IPY_MODEL_ac465cdf9423443e818e1a9e96cc4282",
            "value": "100%"
          }
        },
        "e6671f43925e470c9a8ef83b0e0698fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1bce866b0f84c48b0a50b07ec7b7aff",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee8e10768a18483ea264280e3a0a8ca7",
            "value": 27
          }
        },
        "9a3f0edf677b4ab995e39b97cb98ddda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_785a3a8e98a94c3faf6c5aafd2c9c554",
            "placeholder": "​",
            "style": "IPY_MODEL_c662b0c94859481db977b8ab07f6094d",
            "value": " 27/27 [00:11&lt;00:00,  2.12it/s]"
          }
        },
        "a999788b71514179aed78eed08a43e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24973a24562a44d492e70fe734887450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac465cdf9423443e818e1a9e96cc4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1bce866b0f84c48b0a50b07ec7b7aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8e10768a18483ea264280e3a0a8ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "785a3a8e98a94c3faf6c5aafd2c9c554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c662b0c94859481db977b8ab07f6094d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmitNikhade/AmitNikhade/blob/main/QandA_8.6.22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWkjSjtVKgvM",
        "outputId": "99a6d1c1-31cc-43a1-a9da-a4b6a0404b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pipelines 0.0.1\n",
            "Uninstalling pipelines-0.0.1:\n",
            "  Successfully uninstalled pipelines-0.0.1\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall pipelines -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"/content/a.zip\") as zf:\n",
        "    zf.extractall()"
      ],
      "metadata": {
        "id": "Z-leTeC8nv68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1pPdKwgbBaV4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aweZgxXBDsOQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7dc27b9-2200-480c-efef-b6edc8d9ed46"
      },
      "source": [
        "!pip uninstall transformers -y\n",
        "!pip uninstall sentencepiece\n",
        "!pip install -U transformers==3.0.0\n",
        "!pip install -U sentencepiece==0.1.91\n",
        "!python -m nltk.downloader punkt\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.19.2\n",
            "Uninstalling transformers-4.19.2:\n",
            "  Successfully uninstalled transformers-4.19.2\n",
            "Found existing installation: sentencepiece 0.1.91\n",
            "Uninstalling sentencepiece-0.1.91:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/_sentencepiece.cpython-37m-x86_64-linux-gnu.so\n",
            "    /usr/local/lib/python3.7/dist-packages/sentencepiece-0.1.91.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/sentencepiece.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled sentencepiece-0.1.91\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.0.0\n",
            "  Using cached transformers-3.0.0-py3-none-any.whl (754 kB)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.0.53)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "  Using cached tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "Successfully installed sentencepiece-0.1.96 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sentencepiece",
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Using cached sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: sentencepiece\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.96\n",
            "    Uninstalling sentencepiece-0.1.96:\n",
            "      Successfully uninstalled sentencepiece-0.1.96\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_sentencepiece",
                  "sentencepiece"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import logging\n",
        "from typing import Optional, Dict, Union\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from transformers import(\n",
        "    AutoModelForSeq2SeqLM, \n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class QGPipeline:\n",
        "    \"\"\"Poor man's QG pipeline\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: PreTrainedModel,\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        ans_model: PreTrainedModel,\n",
        "        ans_tokenizer: PreTrainedTokenizer,\n",
        "        qg_format: str,\n",
        "        use_cuda: bool\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.ans_model = ans_model\n",
        "        self.ans_tokenizer = ans_tokenizer\n",
        "\n",
        "        self.qg_format = qg_format\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        if self.ans_model is not self.model:\n",
        "            self.ans_model.to(self.device)\n",
        "\n",
        "        assert self.model.__class__.__name__ in [\"T5ForConditionalGeneration\", \"BartForConditionalGeneration\"]\n",
        "        \n",
        "        if \"T5ForConditionalGeneration\" in self.model.__class__.__name__:\n",
        "            self.model_type = \"t5\"\n",
        "        else:\n",
        "            self.model_type = \"bart\"\n",
        "\n",
        "    def __call__(self, inputs: str):\n",
        "        inputs = \" \".join(inputs.split())\n",
        "        sents, answers = self._extract_answers(inputs)\n",
        "        flat_answers = list(itertools.chain(*answers))\n",
        "        \n",
        "        if len(flat_answers) == 0:\n",
        "          return []\n",
        "\n",
        "        if self.qg_format == \"prepend\":\n",
        "            qg_examples = self._prepare_inputs_for_qg_from_answers_prepend(inputs, answers)\n",
        "        else:\n",
        "            qg_examples = self._prepare_inputs_for_qg_from_answers_hl(sents, answers)\n",
        "        \n",
        "        qg_inputs = [example['source_text'] for example in qg_examples]\n",
        "        questions = self._generate_questions(qg_inputs)\n",
        "        output = [{'answer': example['answer'], 'question': que} for example, que in zip(qg_examples, questions)]\n",
        "        return output\n",
        "    \n",
        "    def _generate_questions(self, inputs):\n",
        "        inputs = self._tokenize(inputs, padding=True, truncation=True)\n",
        "        \n",
        "        outs = self.model.generate(\n",
        "            input_ids=inputs['input_ids'].to(self.device), \n",
        "            attention_mask=inputs['attention_mask'].to(self.device), \n",
        "            max_length=32,\n",
        "            num_beams=4,\n",
        "        )\n",
        "        \n",
        "        questions = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
        "        return questions\n",
        "    \n",
        "    def _extract_answers(self, context):\n",
        "        sents, inputs = self._prepare_inputs_for_ans_extraction(context)\n",
        "        inputs = self._tokenize(inputs, padding=True, truncation=True)\n",
        "\n",
        "        outs = self.ans_model.generate(\n",
        "            input_ids=inputs['input_ids'].to(self.device), \n",
        "            attention_mask=inputs['attention_mask'].to(self.device), \n",
        "            max_length=32,\n",
        "        )\n",
        "        \n",
        "        dec = [self.ans_tokenizer.decode(ids, skip_special_tokens=False) for ids in outs]\n",
        "        answers = [item.split('<sep>') for item in dec]\n",
        "        answers = [i[:-1] for i in answers]\n",
        "        \n",
        "        return sents, answers\n",
        "    \n",
        "    def _tokenize(self,\n",
        "        inputs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512\n",
        "    ):\n",
        "        inputs = self.tokenizer.batch_encode_plus(\n",
        "            inputs, \n",
        "            max_length=max_length,\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            truncation=truncation,\n",
        "            padding=\"max_length\" if padding else False,\n",
        "            pad_to_max_length=padding,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return inputs\n",
        "    \n",
        "    def _prepare_inputs_for_ans_extraction(self, text):\n",
        "        sents = sent_tokenize(text)\n",
        "\n",
        "        inputs = []\n",
        "        for i in range(len(sents)):\n",
        "            source_text = \"extract answers:\"\n",
        "            for j, sent in enumerate(sents):\n",
        "                if i == j:\n",
        "                    sent = \"<hl> %s <hl>\" % sent\n",
        "                source_text = \"%s %s\" % (source_text, sent)\n",
        "                source_text = source_text.strip()\n",
        "            \n",
        "            if self.model_type == \"t5\":\n",
        "                source_text = source_text + \" </s>\"\n",
        "            inputs.append(source_text)\n",
        "\n",
        "        return sents, inputs\n",
        "    \n",
        "    def _prepare_inputs_for_qg_from_answers_hl(self, sents, answers):\n",
        "        inputs = []\n",
        "        for i, answer in enumerate(answers):\n",
        "            if len(answer) == 0: continue\n",
        "            for answer_text in answer:\n",
        "                sent = sents[i]\n",
        "                sents_copy = sents[:]\n",
        "                \n",
        "                answer_text = answer_text.strip()\n",
        "                \n",
        "                ans_start_idx = sent.index(answer_text)\n",
        "                \n",
        "                sent = f\"{sent[:ans_start_idx]} <hl> {answer_text} <hl> {sent[ans_start_idx + len(answer_text): ]}\"\n",
        "                sents_copy[i] = sent\n",
        "                \n",
        "                source_text = \" \".join(sents_copy)\n",
        "                source_text = f\"generate question: {source_text}\" \n",
        "                if self.model_type == \"t5\":\n",
        "                    source_text = source_text + \" </s>\"\n",
        "                \n",
        "                inputs.append({\"answer\": answer_text, \"source_text\": source_text})\n",
        "        \n",
        "        return inputs\n",
        "    \n",
        "    def _prepare_inputs_for_qg_from_answers_prepend(self, context, answers):\n",
        "        flat_answers = list(itertools.chain(*answers))\n",
        "        examples = []\n",
        "        for answer in flat_answers:\n",
        "            source_text = f\"answer: {answer} context: {context}\"\n",
        "            if self.model_type == \"t5\":\n",
        "                source_text = source_text + \" </s>\"\n",
        "            \n",
        "            examples.append({\"answer\": answer, \"source_text\": source_text})\n",
        "        return examples\n",
        "\n",
        "    \n",
        "class MultiTaskQAQGPipeline(QGPipeline):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "    \n",
        "    def __call__(self, inputs: Union[Dict, str]):\n",
        "        if type(inputs) is str:\n",
        "            # do qg\n",
        "            return super().__call__(inputs)\n",
        "        else:\n",
        "            # do qa\n",
        "            return self._extract_answer(inputs[\"question\"], inputs[\"context\"])\n",
        "    \n",
        "    def _prepare_inputs_for_qa(self, question, context):\n",
        "        source_text = f\"question: {question}  context: {context}\"\n",
        "        if self.model_type == \"t5\":\n",
        "            source_text = source_text + \" </s>\"\n",
        "        return  source_text\n",
        "    \n",
        "    def _extract_answer(self, question, context):\n",
        "        source_text = self._prepare_inputs_for_qa(question, context)\n",
        "        inputs = self._tokenize([source_text], padding=False)\n",
        "    \n",
        "        outs = self.model.generate(\n",
        "            input_ids=inputs['input_ids'].to(self.device), \n",
        "            attention_mask=inputs['attention_mask'].to(self.device), \n",
        "            max_length=16,\n",
        "        )\n",
        "\n",
        "        answer = self.tokenizer.decode(outs[0], skip_special_tokens=True)\n",
        "        return answer\n",
        "\n",
        "\n",
        "class E2EQGPipeline:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: PreTrainedModel,\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        use_cuda: bool\n",
        "    ) :\n",
        "\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        assert self.model.__class__.__name__ in [\"T5ForConditionalGeneration\", \"BartForConditionalGeneration\"]\n",
        "        \n",
        "        if \"T5ForConditionalGeneration\" in self.model.__class__.__name__:\n",
        "            self.model_type = \"t5\"\n",
        "        else:\n",
        "            self.model_type = \"bart\"\n",
        "        \n",
        "        self.default_generate_kwargs = {\n",
        "            \"max_length\": 256,\n",
        "            \"num_beams\": 4,\n",
        "            \"length_penalty\": 1.5,\n",
        "            \"no_repeat_ngram_size\": 3,\n",
        "            \"early_stopping\": True,\n",
        "        }\n",
        "    \n",
        "    def __call__(self, context: str, **generate_kwargs):\n",
        "        inputs = self._prepare_inputs_for_e2e_qg(context)\n",
        "\n",
        "        # TODO: when overrding default_generate_kwargs all other arguments need to be passsed\n",
        "        # find a better way to do this\n",
        "        if not generate_kwargs:\n",
        "            generate_kwargs = self.default_generate_kwargs\n",
        "        \n",
        "        input_length = inputs[\"input_ids\"].shape[-1]\n",
        "        \n",
        "        # max_length = generate_kwargs.get(\"max_length\", 256)\n",
        "        # if input_length < max_length:\n",
        "        #     logger.warning(\n",
        "        #         \"Your max_length is set to {}, but you input_length is only {}. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\".format(\n",
        "        #             max_length, input_length\n",
        "        #         )\n",
        "        #     )\n",
        "\n",
        "        outs = self.model.generate(\n",
        "            input_ids=inputs['input_ids'].to(self.device), \n",
        "            attention_mask=inputs['attention_mask'].to(self.device),\n",
        "            **generate_kwargs\n",
        "        )\n",
        "\n",
        "        prediction = self.tokenizer.decode(outs[0], skip_special_tokens=True)\n",
        "        questions = prediction.split(\"<sep>\")\n",
        "        questions = [question.strip() for question in questions[:-1]]\n",
        "        return questions\n",
        "    \n",
        "    def _prepare_inputs_for_e2e_qg(self, context):\n",
        "        source_text = f\"generate questions: {context}\"\n",
        "        if self.model_type == \"t5\":\n",
        "            source_text = source_text + \" </s>\"\n",
        "        \n",
        "        inputs = self._tokenize([source_text], padding=False)\n",
        "        return inputs\n",
        "    \n",
        "    def _tokenize(\n",
        "        self,\n",
        "        inputs,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512\n",
        "    ):\n",
        "        inputs = self.tokenizer.batch_encode_plus(\n",
        "            inputs, \n",
        "            max_length=max_length,\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            truncation=truncation,\n",
        "            padding=\"max_length\" if padding else False,\n",
        "            pad_to_max_length=padding,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return inputs\n",
        "\n",
        "\n",
        "SUPPORTED_TASKS = {\n",
        "    \"question-generation\": {\n",
        "        \"impl\": QGPipeline,\n",
        "        \"default\": {\n",
        "            \"model\": \"valhalla/t5-small-qg-hl\",\n",
        "            \"ans_model\": \"valhalla/t5-small-qa-qg-hl\",\n",
        "        }\n",
        "    },\n",
        "    \"multitask-qa-qg\": {\n",
        "        \"impl\": MultiTaskQAQGPipeline,\n",
        "        \"default\": {\n",
        "            \"model\": \"valhalla/t5-small-qa-qg-hl\",\n",
        "        }\n",
        "    },\n",
        "    \"e2e-qg\": {\n",
        "        \"impl\": E2EQGPipeline,\n",
        "        \"default\": {\n",
        "            \"model\": \"valhalla/t5-small-e2e-qg\",\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "def pipeline(\n",
        "    task: str,\n",
        "    model: Optional = None,\n",
        "    tokenizer: Optional[Union[str, PreTrainedTokenizer]] = None,\n",
        "    qg_format: Optional[str] = \"highlight\",\n",
        "    ans_model: Optional = None,\n",
        "    ans_tokenizer: Optional[Union[str, PreTrainedTokenizer]] = None,\n",
        "    use_cuda: Optional[bool] = True,\n",
        "    **kwargs,\n",
        "):\n",
        "    # Retrieve the task\n",
        "    if task not in SUPPORTED_TASKS:\n",
        "        raise KeyError(\"Unknown task {}, available tasks are {}\".format(task, list(SUPPORTED_TASKS.keys())))\n",
        "\n",
        "    targeted_task = SUPPORTED_TASKS[task]\n",
        "    task_class = targeted_task[\"impl\"]\n",
        "\n",
        "    # Use default model/config/tokenizer for the task if no model is provided\n",
        "    if model is None:\n",
        "        model = targeted_task[\"default\"][\"model\"]\n",
        "    \n",
        "    # Try to infer tokenizer from model or config name (if provided as str)\n",
        "    if tokenizer is None:\n",
        "        if isinstance(model, str):\n",
        "            tokenizer = model\n",
        "        else:\n",
        "            # Impossible to guest what is the right tokenizer here\n",
        "            raise Exception(\n",
        "                \"Impossible to guess which tokenizer to use. \"\n",
        "                \"Please provided a PretrainedTokenizer class or a path/identifier to a pretrained tokenizer.\"\n",
        "            )\n",
        "    \n",
        "    # Instantiate tokenizer if needed\n",
        "    if isinstance(tokenizer, (str, tuple)):\n",
        "        if isinstance(tokenizer, tuple):\n",
        "            # For tuple we have (tokenizer name, {kwargs})\n",
        "            tokenizer = AutoTokenizer.from_pretrained(tokenizer[0], **tokenizer[1])\n",
        "        else:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
        "    \n",
        "    # Instantiate model if needed\n",
        "    if isinstance(model, str):\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
        "    \n",
        "    if task == \"question-generation\":\n",
        "        if ans_model is None:\n",
        "            # load default ans model\n",
        "            ans_model = targeted_task[\"default\"][\"ans_model\"]\n",
        "            ans_tokenizer = AutoTokenizer.from_pretrained(ans_model)\n",
        "            ans_model = AutoModelForSeq2SeqLM.from_pretrained(ans_model)\n",
        "        else:\n",
        "            # Try to infer tokenizer from model or config name (if provided as str)\n",
        "            if ans_tokenizer is None:\n",
        "                if isinstance(ans_model, str):\n",
        "                    ans_tokenizer = ans_model\n",
        "                else:\n",
        "                    # Impossible to guest what is the right tokenizer here\n",
        "                    raise Exception(\n",
        "                        \"Impossible to guess which tokenizer to use. \"\n",
        "                        \"Please provided a PretrainedTokenizer class or a path/identifier to a pretrained tokenizer.\"\n",
        "                    )\n",
        "            \n",
        "            # Instantiate tokenizer if needed\n",
        "            if isinstance(ans_tokenizer, (str, tuple)):\n",
        "                if isinstance(ans_tokenizer, tuple):\n",
        "                    # For tuple we have (tokenizer name, {kwargs})\n",
        "                    ans_tokenizer = AutoTokenizer.from_pretrained(ans_tokenizer[0], **ans_tokenizer[1])\n",
        "                else:\n",
        "                    ans_tokenizer = AutoTokenizer.from_pretrained(ans_tokenizer)\n",
        "\n",
        "            if isinstance(ans_model, str):\n",
        "                ans_model = AutoModelForSeq2SeqLM.from_pretrained(ans_model)\n",
        "    \n",
        "    if task == \"e2e-qg\":\n",
        "        return task_class(model=model, tokenizer=tokenizer, use_cuda=use_cuda)\n",
        "    elif task == \"question-generation\":\n",
        "        return task_class(model=model, tokenizer=tokenizer, ans_model=ans_model, ans_tokenizer=ans_tokenizer, qg_format=qg_format, use_cuda=use_cuda)\n",
        "    else:\n",
        "        return task_class(model=model, tokenizer=tokenizer, ans_model=model, ans_tokenizer=tokenizer, qg_format=qg_format, use_cuda=use_cuda)"
      ],
      "metadata": {
        "id": "74D9SM3VrG3j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp =pipeline(\"question-generation\", model=\"valhalla/t5-base-qg-hl\")"
      ],
      "metadata": {
        "id": "nwD4dg5ZuEj9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open(\"/content/sh.txt\")\n",
        "# f = f.read().strip().replace(\"\\n\",\"\").replace(\"  \",\"\")\n",
        "# text= f\n",
        "text = \"\"\"Donning many hats of a speaker, author, entrepreneur and navigator, Yogesh is among Asia’s top leadership and business strategy authorities whose work has impacted entrepreneurs and enterprises across the globe. With a master’s degree in Transactional Analysis, Yogesh is a change catalyst who consults internationally to large companies, small and medium enterprises, and government organizations on his unique model of people and business growth & transformation, business model re-innovation, and impactful leadership development.\n",
        "Yogesh began his career as an entrepreneur at the early age of 16, at his father’s shop after which, he ran an adventure campsite, and then, a real estate company. He took every success as a blessing and every failure as a learning.\n",
        "Yogesh is an avid reader and his keen interest in Psychology helped him understand business patterns and business behaviors of people. He learned his basic lessons of Psychology based on the Freudian theory of Transactional Analysis. Based on his observations of people behaviors, he has created effective models like the “Leadership Imbalance Model ®” and the “CPC Model of Business Scalability ®.” His ability to understand the scientific reasons behind people’s behavioral patterns helped him to gain the confidence of all stakeholders and handle complex situations in businesses where he advised, consulted and trained.\n",
        "Yogesh’s clear, data-driven methodologies have helped companies across the globe design and implement growth strategies and drive real results, both in terms of building capability and significant financial returns.\n",
        "Consistent growth is one of his greatest motivators, and being equally humble and assertive has attracted a lot of leaders to learn from him. He has dedicated his life to helping leaders seek clarity and build tolerance through his signature concept of “What great leaders do.” He focuses on developing and correcting behaviors and habits in leaders in order to create the impact required at the marketplace. His “Leadership Imbalance Model ®” helps leaders realize “What they are doing but shouldn’t do.”\n",
        "His education, observations of the modern world, corporate experience of solving problems, innate curiosity and eagerness to assist people to attain their true potential has led him to become a dependable leader, entrepreneur and a trusted advisor to his clients worldwide.Yogesh began his career as an entrepreneur at the early age of 16, at his father’s shop after which, he ran an adventure campsite, and then, a real estate company. He took every success as a blessing and every failure as a learning.\n",
        "Yogesh is an avid reader and his keen interest in Psychology helped him understand business patterns and business behaviors of people. He learned his basic lessons of Psychology based on the Freudian theory of Transactional Analysis. Based on his observations of people behaviors, he has created effective models like the “Leadership Imbalance Model ®” and the “CPC Model of Business Scalability ®.” His ability to understand the scientific reasons behind people’s behavioral patterns helped him to gain the confidence of all stakeholders and handle complex situations in businesses where he advised, consulted and trained.\n",
        "Yogesh’s clear, data-driven methodologies have helped companies across the globe design and implement growth strategies and drive real results, both in terms of building capability and significant financial returns.\n",
        "Consistent growth is one of his greatest motivators, and being equally humble and assertive has attracted a lot of leaders to learn from him. He has dedicated his life to helping leaders seek clarity and build tolerance through his signature concept of “What great leaders do.” He focuses on developing and correcting behaviors and habits in leaders in order to create the impact required at the marketplace. His “Leadership Imbalance Model ®” helps leaders realize “What they are doing but shouldn’t do.”His education, observations of the modern world, corporate experience of solving problems, innate curiosity and eagerness to assist people to attain their true potential has led him to become a dependable leader, entrepreneur and a trusted advisor to his clients worldwide.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RAb2OjXuucJA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(nlp(\"Day one: finding your breath.“Take a moment to listen to your breathing,” the recording of Dr. McCourt said, through the car’s speakers. “Don’t try to control it, just feel the air as it enters and exits your nose.”Garry slammed his brakes and his horn. Just like the driver ahead. Just like the driver behind.“Stop fucking honking at me asswipe!” he screamed over his shoulder. He could see the driver behind him, screaming himself red. Look at this guy! What an idiot.Somewhere a light turned green.\"))"
      ],
      "metadata": {
        "id": "TgJ2eBQTGT86"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import uuid\n",
        "data = []\n",
        "text_ = text.split('.')\n",
        "tm = 0\n",
        "for n,s in enumerate(tqdm_notebook(text_)):\n",
        "  # print(nlp(s))\n",
        "  # if n == 2000:\n",
        "  #   break\n",
        "  # else:\n",
        "    # print(n)\n",
        "  try:\n",
        "    qa = nlp(s)\n",
        "    print(qa)\n",
        "    for i in qa:\n",
        "      if str(i['answer']) in str(s):\n",
        "        # print([str(uuid.uuid4()).replace(\"-\",\"\"),s,i['question'],i['answer'],str(text.index(i['answer']))])\n",
        "        data.append([str(uuid.uuid4()).replace(\"-\",\"\"),s,i['question'],i['answer'],str(text.index(i['answer']))])\n",
        "          # tm = tm+1\n",
        "      \n",
        "          \n",
        "  except:\n",
        "    pass \n",
        "\n",
        "  \n",
        "     \n",
        "  # # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "6d1d6eae623a4bc78086b32fbcf232ce",
            "a9c935703527464e9d76ea2266822466",
            "e6671f43925e470c9a8ef83b0e0698fb",
            "9a3f0edf677b4ab995e39b97cb98ddda",
            "a999788b71514179aed78eed08a43e68",
            "24973a24562a44d492e70fe734887450",
            "ac465cdf9423443e818e1a9e96cc4282",
            "d1bce866b0f84c48b0a50b07ec7b7aff",
            "ee8e10768a18483ea264280e3a0a8ca7",
            "785a3a8e98a94c3faf6c5aafd2c9c554",
            "c662b0c94859481db977b8ab07f6094d"
          ]
        },
        "id": "uEd7QiXFxuDG",
        "outputId": "785c43f6-168a-4176-dd18-760505f51f96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/27 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d1d6eae623a4bc78086b32fbcf232ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1500: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beam_id = beam_token_id // vocab_size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': 'Yogesh', 'question': \"Who is one of Asia's top leadership and business strategy authorities?\"}]\n",
            "[{'answer': 'Transactional Analysis', 'question': \"What is Yogesh's master's degree in?\"}]\n",
            "[{'answer': 'entrepreneur', 'question': 'What occupation did Yogesh begin his career as?'}, {'answer': '16', 'question': 'At what age did Yogesh start his career as an entrepreneur?'}]\n",
            "[{'answer': 'blessing', 'question': 'What did he take every success as?'}]\n",
            "[{'answer': 'Freudian theory of Transactional Analysis', 'question': 'What theory did he use to learn basic lessons of Psychology?'}, {'answer': 'Freudian theory of Transactional Analysis', 'question': 'What theory did he use to learn basic lessons of Psychology?'}]\n",
            "[{'answer': 'Leadership Imbalance Model ®', 'question': 'What is the name of the model that he has created?'}]\n",
            "[{'answer': 'understand the scientific reasons behind people’s behavioral patterns', 'question': 'How did he gain the confidence of all stakeholders?'}]\n",
            "[{'answer': 'building capability and significant financial returns', 'question': 'Yogesh’s data-driven methodologies have helped companies drive real results in terms of what two things?'}, {'answer': 'Yogesh', 'question': 'Who has helped companies across the globe design and implement growth strategies and drive real results?'}]\n",
            "[{'answer': 'Consistent growth', 'question': 'What is one of his greatest motivators?'}]\n",
            "[{'answer': 'developing and correcting behaviors and habits', 'question': 'What does he focus on in leaders in order to create the impact required at the marketplace?'}]\n",
            "[{'answer': 'Leadership Imbalance Model ®', 'question': 'What is the name of the model that helps leaders realize what they are doing but shouldn’t do?'}]\n",
            "[{'answer': 'a dependable leader, entrepreneur and a trusted advisor', 'question': 'What has he become to his clients worldwide?'}]\n",
            "[{'answer': 'entrepreneur', 'question': 'What occupation did Yogesh begin his career as?'}, {'answer': '16', 'question': 'At what age did Yogesh start his career as an entrepreneur?'}]\n",
            "[{'answer': 'blessing', 'question': 'What did he take every success as?'}]\n",
            "[{'answer': 'Freudian theory of Transactional Analysis', 'question': 'What theory did he use to learn basic lessons of Psychology?'}, {'answer': 'Freudian theory of Transactional Analysis', 'question': 'What theory did he use to learn basic lessons of Psychology?'}]\n",
            "[{'answer': 'Leadership Imbalance Model ®', 'question': 'What is the name of the model that he has created?'}]\n",
            "[{'answer': 'understand the scientific reasons behind people’s behavioral patterns', 'question': 'How did he gain the confidence of all stakeholders?'}]\n",
            "[{'answer': 'building capability and significant financial returns', 'question': 'Yogesh’s data-driven methodologies have helped companies drive real results in terms of what two things?'}, {'answer': 'Yogesh', 'question': 'Who has helped companies across the globe design and implement growth strategies and drive real results?'}]\n",
            "[{'answer': 'Consistent growth', 'question': 'What is one of his greatest motivators?'}]\n",
            "[{'answer': 'developing and correcting behaviors and habits', 'question': 'What does he focus on in leaders in order to create the impact required at the marketplace?'}]\n",
            "[{'answer': 'Leadership Imbalance Model ®', 'question': 'What is the name of the model that helps leaders realize what they are doing but shouldn’t do?'}]\n",
            "[{'answer': 'a dependable leader, entrepreneur and a trusted advisor', 'question': 'What has he become to his clients worldwide?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "DQ2bEX8tHam5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        " \n",
        "# intialise data of lists.\n",
        "data = {\n",
        "    # 'id':[i[0] for i in data],\n",
        "    #     'context':[i[1] for i in data],\n",
        "        'question':[i[2] for i in data],\n",
        "        'answer_text':[i[3] for i in data],\n",
        "        # 'answer_start':[i[4] for i in data],\n",
        "        # 'answers':[{'answer_start':[int(i[4])],'text':[i[3]]} for i in data]\n",
        "    \n",
        "        }\n",
        " \n",
        "# Create DataFrame\n",
        "train = pd.DataFrame(data)\n",
        " \n",
        "# Print the output.\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "PO2L1TZ8tY-z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "HMgtj7X1GRqK",
        "outputId": "8007e704-cc6f-4530-839b-093c10df0c83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0   Who is one of Asia's top leadership and busine...   \n",
              "1                What is Yogesh's master's degree in?   \n",
              "2     What occupation did Yogesh begin his career as?   \n",
              "3   At what age did Yogesh start his career as an ...   \n",
              "4                  What did he take every success as?   \n",
              "5   What theory did he use to learn basic lessons ...   \n",
              "6   What theory did he use to learn basic lessons ...   \n",
              "7   What is the name of the model that he has crea...   \n",
              "8   How did he gain the confidence of all stakehol...   \n",
              "9   Yogesh’s data-driven methodologies have helped...   \n",
              "10  Who has helped companies across the globe desi...   \n",
              "11            What is one of his greatest motivators?   \n",
              "12  What does he focus on in leaders in order to c...   \n",
              "13  What is the name of the model that helps leade...   \n",
              "14       What has he become to his clients worldwide?   \n",
              "15    What occupation did Yogesh begin his career as?   \n",
              "16  At what age did Yogesh start his career as an ...   \n",
              "17                 What did he take every success as?   \n",
              "18  What theory did he use to learn basic lessons ...   \n",
              "19  What theory did he use to learn basic lessons ...   \n",
              "20  What is the name of the model that he has crea...   \n",
              "21  How did he gain the confidence of all stakehol...   \n",
              "22  Yogesh’s data-driven methodologies have helped...   \n",
              "23  Who has helped companies across the globe desi...   \n",
              "24            What is one of his greatest motivators?   \n",
              "25  What does he focus on in leaders in order to c...   \n",
              "26  What is the name of the model that helps leade...   \n",
              "27       What has he become to his clients worldwide?   \n",
              "\n",
              "                                          answer_text  \n",
              "0                                              Yogesh  \n",
              "1                              Transactional Analysis  \n",
              "2                                        entrepreneur  \n",
              "3                                                  16  \n",
              "4                                            blessing  \n",
              "5           Freudian theory of Transactional Analysis  \n",
              "6           Freudian theory of Transactional Analysis  \n",
              "7                        Leadership Imbalance Model ®  \n",
              "8   understand the scientific reasons behind peopl...  \n",
              "9   building capability and significant financial ...  \n",
              "10                                             Yogesh  \n",
              "11                                  Consistent growth  \n",
              "12     developing and correcting behaviors and habits  \n",
              "13                       Leadership Imbalance Model ®  \n",
              "14  a dependable leader, entrepreneur and a truste...  \n",
              "15                                       entrepreneur  \n",
              "16                                                 16  \n",
              "17                                           blessing  \n",
              "18          Freudian theory of Transactional Analysis  \n",
              "19          Freudian theory of Transactional Analysis  \n",
              "20                       Leadership Imbalance Model ®  \n",
              "21  understand the scientific reasons behind peopl...  \n",
              "22  building capability and significant financial ...  \n",
              "23                                             Yogesh  \n",
              "24                                  Consistent growth  \n",
              "25     developing and correcting behaviors and habits  \n",
              "26                       Leadership Imbalance Model ®  \n",
              "27  a dependable leader, entrepreneur and a truste...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69472a6b-2ba1-41a0-bfaf-6f9934d98245\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who is one of Asia's top leadership and busine...</td>\n",
              "      <td>Yogesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Yogesh's master's degree in?</td>\n",
              "      <td>Transactional Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What occupation did Yogesh begin his career as?</td>\n",
              "      <td>entrepreneur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>At what age did Yogesh start his career as an ...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What did he take every success as?</td>\n",
              "      <td>blessing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What theory did he use to learn basic lessons ...</td>\n",
              "      <td>Freudian theory of Transactional Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What theory did he use to learn basic lessons ...</td>\n",
              "      <td>Freudian theory of Transactional Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the name of the model that he has crea...</td>\n",
              "      <td>Leadership Imbalance Model ®</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How did he gain the confidence of all stakehol...</td>\n",
              "      <td>understand the scientific reasons behind peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Yogesh’s data-driven methodologies have helped...</td>\n",
              "      <td>building capability and significant financial ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Who has helped companies across the globe desi...</td>\n",
              "      <td>Yogesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is one of his greatest motivators?</td>\n",
              "      <td>Consistent growth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What does he focus on in leaders in order to c...</td>\n",
              "      <td>developing and correcting behaviors and habits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What is the name of the model that helps leade...</td>\n",
              "      <td>Leadership Imbalance Model ®</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What has he become to his clients worldwide?</td>\n",
              "      <td>a dependable leader, entrepreneur and a truste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What occupation did Yogesh begin his career as?</td>\n",
              "      <td>entrepreneur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>At what age did Yogesh start his career as an ...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What did he take every success as?</td>\n",
              "      <td>blessing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What theory did he use to learn basic lessons ...</td>\n",
              "      <td>Freudian theory of Transactional Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What theory did he use to learn basic lessons ...</td>\n",
              "      <td>Freudian theory of Transactional Analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What is the name of the model that he has crea...</td>\n",
              "      <td>Leadership Imbalance Model ®</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>How did he gain the confidence of all stakehol...</td>\n",
              "      <td>understand the scientific reasons behind peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Yogesh’s data-driven methodologies have helped...</td>\n",
              "      <td>building capability and significant financial ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Who has helped companies across the globe desi...</td>\n",
              "      <td>Yogesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>What is one of his greatest motivators?</td>\n",
              "      <td>Consistent growth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>What does he focus on in leaders in order to c...</td>\n",
              "      <td>developing and correcting behaviors and habits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>What is the name of the model that helps leade...</td>\n",
              "      <td>Leadership Imbalance Model ®</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>What has he become to his clients worldwide?</td>\n",
              "      <td>a dependable leader, entrepreneur and a truste...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69472a6b-2ba1-41a0-bfaf-6f9934d98245')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69472a6b-2ba1-41a0-bfaf-6f9934d98245 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69472a6b-2ba1-41a0-bfaf-6f9934d98245');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('file_dr_yo.csv')"
      ],
      "metadata": {
        "id": "JlEqwcV7IU6P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall transformers\n",
        "# !pip install -U transformers==4.19.2\n",
        "\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
        "data1 = []\n",
        "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\"\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(model_name)\n",
        "model1 = AutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "\n",
        "def get_question(answer, context, max_length=64):\n",
        "  input_text = \"answer: %s  context: %s </s>\" % (answer, context)\n",
        "  features = tokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "  output = model.generate(input_ids=features['input_ids'], \n",
        "               attention_mask=features['attention_mask'],\n",
        "               max_length=max_length)\n",
        "\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "\n",
        "context = \"Yogesh is among Asia’s top leadership and business strategy authorities whose work has impacted entrepreneurs and enterprises across the globe.\"\n",
        "for i in context.split(\" \"):\n",
        "  # print(get_question(i, context)[10:])\n",
        "  input = f\"question: {(get_question(i, context)[10:])} context: {context}\"\n",
        "  encoded_input = tokenizer1([input],\n",
        "                              return_tensors='pt',\n",
        "                              max_length=512,\n",
        "                              truncation=True)\n",
        "  output = model1.generate(input_ids = encoded_input.input_ids,\n",
        "                              attention_mask = encoded_input.attention_mask)\n",
        "  output = tokenizer1.decode(output[0], skip_special_tokens=True)\n",
        "  print((get_question(i, context)[10:]),output)\n",
        "  data1.append([(get_question(i, context)[10:]),output])\n",
        "\n",
        "# answer = \"Asia’s top leadership and business strategy authorities\"\n",
        "\n",
        "# get_question(answer, context)"
      ],
      "metadata": {
        "id": "9gsCsDRXnLfP",
        "outputId": "f7f83754-7978-464d-d7a9-67659d1f9acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:925: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is one of Asia's top leadership and business strategy authorities? Yogesh\n",
            "What is Yogesh's profession? leadership and business strategy authorities\n",
            "Where does Yogesh rank among Asia's top leadership and business strategy authorities? \n",
            "Yogesh is one of which countries top leadership and business strategy authorities? Asia\n",
            "What is Yogesh's rank in Asia? Top leadership and business strategy authorities\n",
            "What is Yogesh's profession? leadership and business strategy authorities\n",
            "What is Yogesh's professional background? leadership and business strategy\n",
            "What type of strategy has Yogesh developed? leadership and business strategy\n",
            "What is Yogesh's specialty? leadership and business strategy\n",
            "What is Yogesh a part of? Asia’s top leadership and business strategy authorities\n",
            "Who is Yogesh? Asia’s top leadership and business strategy authorities\n",
            "What has Yogesh done that has impacted entrepreneurs and enterprises across the globe? Yogesh has led and business strategy authorities.\n",
            "How has Yogesh's work impacted entrepreneurs and enterprises? across the globe\n",
            "How has Yogesh's work affected entrepreneurs and enterprises? \n",
            "Yogesh has impacted what types of businesses? Entrepreneurs and enterprises\n",
            "What is Yogesh's professional background? leadership and business strategy\n",
            "Yogesh has impacted entrepreneurs and what else? enterprises across the globe\n",
            "Where has Yogesh's work impacted entrepreneurs and enterprises? across the globe\n",
            "What is Yogesh's profession? leadership and business strategy authorities\n",
            "Yogesh has impacted entrepreneurs and enterprises across what continent? Asia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        " \n",
        "        'question':[i[0] for i in data1],\n",
        "        'answer_text':[i[1] for i in data1],\n",
        "   \n",
        "        }\n",
        " \n",
        "# Create DataFrame\n",
        "train1 = pd.DataFrame(data)\n",
        " "
      ],
      "metadata": {
        "id": "r_WuzlUjqoWH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.concat([train, train1], axis=0)"
      ],
      "metadata": {
        "id": "CNqDPwZmvOHp",
        "outputId": "0ed7882f-1b67-4203-ed77-f6db88dff937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a9ecbf8d7b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7XZv91kawG0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}